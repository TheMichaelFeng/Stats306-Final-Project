---
title: "DATASCI 306, Fall 2024, Final Group Project"
author: "Your group number and each team member names"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

Throughout this course, you've dedicated yourself to refining your analytical abilities using R programming language. These skills are highly coveted in today's job market!  

Now, for the semester project, you'll apply your learning to craft a compelling `Data Story` that can enrich your portfolio and impress prospective employers. Collaborating with a team (up to 5 members of your choosing), you'll construct a Data Story akin to the example provided here: <https://ourworldindata.org/un-population-2024-revision>

Data is already in the `data` folder. This data is downloaded from: <https://population.un.org/wpp/Download/Standard/MostUsed/>

You'll conduct Exploratory Data Analysis (EDA) on the provided data. The provided article already includes 6 diagrams.  Show either the line or the map option for these 6 charts. You may ignore the table view. I'm also interested in seeing how each team will expand upon the initial analysis and generate additional 12 insightful charts that includes US and any other region or country that the author did not show.  For e.g., one question you may want to answer is; US population is expected to increase to 421 million by 2100. You may want to show how the fertility rate and migration may be contributing to this increase in population.

**Deliverable**

**1. Requirement-1 (2 pt) **
Import the data given in the .xlxs file into two separate dataframes;

* one dataframe to show data from the `Estimates` tab 
* one dataframe to show data from the `Medium variant` tab 

Hint: Some of the steps you may take while importing include:

* skip the first several comment lines in the spread sheet
* Importing the data as text first and then converting the relevant columns to different datatypes in step 2 below.

```{r}
library(readxl)
library(tidyr)

estimates_table <- read_excel("data/WPP2024_GEN_F01_DEMOGRAPHIC_INDICATORS_COMPACT.xlsx", sheet = "Estimates", skip = 16, col_types = "text")
medium_variant_table <- read_excel("data/WPP2024_GEN_F01_DEMOGRAPHIC_INDICATORS_COMPACT.xlsx", sheet = "Medium variant", skip = 16, col_types = "text")

```
**2. Requirement-2 (5 pt)**

You should show at least 5 steps you adopt to clean and/or transform the data. Your cleaning should include:

* Renaming column names to make it more readable; removing space, making it lowercase or completely giving a different short name; all are acceptable.
* Removing rows that are irrelevant; look at rows that have Type value as 'Label/Separator'; are those rows required?
* Removing columns that are redundant; For e.g., variant column
* Converting text values to numeric on the columns that need this transformation

You could also remove the countries/regions that you are not interested in exploring in this step and re-save a smaller file in the same `data` folder, with a different name so that working with it becomes easier going forward.

Explain your reasoning for each clean up step.
Takes in col names and gets rid of 
```{r}
library(dplyr)
#Explanation: Takes in a data frames and cleans up the column names 
rename_cols <- function(df) {
  df <- df |>
    rename_with(~ gsub(" ", "_", .)) |>
    rename_with(~ gsub("[^[:alnum:]_]", "", .)) |>
    rename_with(~ tolower(.))
  return(df)
}

estimates_clean <- rename_cols(estimates_table)
medium_clean <- rename_cols(medium_variant_table)
```

```{r}
# Filters out rows where 'type' column has 'Label/Separator' to make it organized
estimates_clean <- estimates_clean[estimates_clean$type != "Label/Separator", ]
medium_clean <- medium_clean[medium_clean$type != "Label/Separator", ]
```

```{r}
#Get rid of some uneccessary rows
clean_cols <- function(df) {
  df %>% select(-c("variant", "notes", "location_code", "iso3_alphacode", "iso2_alphacode", "sdmx_code", "type", "parent_code"))
}

estimates_clean <- clean_cols(estimates_clean)
medium_clean <- clean_cols(medium_clean)
```


```{r}
#Takes in a dataframe and convert n -> N as numeric. Then reapply the omit function to get rid of NA values created
convert_columns_to_numeric <- function(data, n) {
  data[(n + 1):ncol(data)] <- lapply(data[(n + 1):ncol(data)], function(x) {
    as.numeric(as.character(x))
  })
  return(data)
}
  
estimates_clean <- convert_columns_to_numeric(estimates_clean, 3)
medium_clean <- convert_columns_to_numeric(medium_clean, 3)
```

**3.  Requirement-3 (3 pt)**
Replicate the 6 diagrams shown in the article.  Show only the '2024' projection values where ever you have both '2022' and '2024' displayed. 
Show only the diagrams that are shown on the webpage with default options.
Graph 1: 
```{r}
library(ggplot2)
library(dplyr)
library(scales)
medium_clean |>
  filter(region_subregion_country_or_area_ == "World") |> mutate(year = as.numeric(year)) |> ggplot(aes(x = year, y = total_population_as_of_1_january_thousands)) + geom_line(group = 1, color = "blue") + geom_point(color = "blue") +
  labs(
    title = "Total Population - World",x = "Year", y = "Population (Billions)") + scale_x_continuous(breaks = c(2024, 2040, 2050, 2060, 2070, 2080, 2090, 2100)) +
  scale_y_continuous(breaks = c(8.5e6, 9e6, 9.5e6, 10e6), labels = c("8.5B", "9B", "9.5B", "10B"))
```
Graph 2
```{r} 
#This one needs fixing
medium_clean |>
  filter(region_subregion_country_or_area_ %in% c("World", "Africa", "Asia", "Europe", "Northern America", "Latin America and the Caribbean")) |> mutate(year = as.numeric(year)) |> ggplot(aes(x = year, y = total_population_as_of_1_january_thousands)) + geom_line(group = 1, color = "blue") + geom_point(color = "blue") +
  labs(
    title = "Total Population - World",x = "Year", y = "Population (Billions)") + scale_x_continuous(breaks = c(2024, 2050, 2080)) + facet_wrap(~region_subregion_country_or_area_)
```
Graph 3
```{r}



```

Graph 4 
```{r}
library(ggplot2)
library(dplyr)

# Filter for India and China population data from medium_clean
graph_4_data <- medium_clean %>%
  filter(region_subregion_country_or_area_ %in% c("India", "China")) %>%
  mutate(
    year = as.numeric(year), # Ensure 'year' is numeric
    population_billions = total_population_as_of_1_july_thousands / 1e6 # Convert thousands to billions
  )

# Create the line graph
ggplot(graph_4_data, aes(x = year, y = population_billions, color = region_subregion_country_or_area_)) +
  geom_line(size = 1) + # Add lines
  geom_point(size = 1.5) + # Add points
  scale_color_manual(values = c("India" = "red", "China" = "blue")) + # Match colors to the original graph
  labs(
    title = "Population, 1950 to 2100",
    subtitle = "Projections from 2024 onwards are based on the UN's medium scenario.",
    x = "Year",
    y = "Population (billions)",
    color = "Country"
  ) +
  scale_x_continuous(breaks = seq(1950, 2100, by = 10)) + # X-axis ticks every 10 years
  scale_y_continuous(breaks = seq(0, 2, by = 0.2)) + # Y-axis ticks every 0.2 billion
  theme_minimal() + # Clean theme
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    plot.subtitle = element_text(hjust = 0.5, size = 10),
    legend.position = "bottom"
  )

```

Graph 5

```{r}
#needs fixed
countries <- c("World", "Africa", "Asia", "Europe", "Northern America", "Latin America and the Caribbean")
estimates_clean |> 
  select(year, life_expectancy_at_birth_both_sexes_years, region_subregion_country_or_area_) |>
  filter(region_subregion_country_or_area_ %in% countries) |>
  ggplot(aes(x = as.numeric(year),  life_expectancy_at_birth_both_sexes_years)) + geom_point()
```

Graph 6
```{r}
estimates_clean |>
  filter(region_subregion_country_or_area_ == "Ukraine") |>
  select(year, net_number_of_migrants_thousands) |>
  ggplot(aes(x = as.numeric(year), y = net_number_of_migrants_thousands))+ 
  geom_point() + geom_line() + scale_x_continuous(breaks = c(1950, 1960, 1970, 1980, 1990, 2000, 2010, 2023)) + labs(title = "Annual net migration in Ukraine, 1950 to 2023", x = "Year", y = "Net Migration") + scale_y_continuous(breaks = c(0, -2000, -4000), labels = c("0", "-2 Million", "- 4 million"))

```
**4.  Requirement-4 (12 pt)**

Select United States related data, and any other country or region(s) of your choosing to perform EDA. Chart at least 12 additional diagrams that may show relationships like correlations, frequencies, trend charts, between various variables with plots of at least 3 different types (line, heatmap, pie, etc.). Every plot should have a title and the x/y axis should have legible labels without any label overlaps for full credit. 

Summarize your interpretations after each chart.


**5. Requirement-5 (2 pt)**
Having developed a strong understanding of your data, you'll now create a machine learning (ML) model to predict a specific metric. This involves selecting the most relevant variables from your dataset.

The UN's World Population Prospects provides a range of projected scenarios of population change. These rely on different assumptions in fertility, mortality and/or migration patterns to explore different demographic futures. Check this link for more info: https://population.un.org/wpp/DefinitionOfProjectionScenarios

You can choose to predict the same metric the UN provides (e.g., future population using fertility, mortality, and migration data). Compare your model's predictions to the UN's. 

How significantly do your population projections diverge from those of the United Nations? Provide a comparison of the two.  If you choose a different projection for which there is no UN data to compare with, then this comparison is not required.


**6.  Requirement-5 (1 pt)**

**Conclusion**

Your analysis should conclude with a summary of key findings. I'm especially interested in any novel insights you uncover that go beyond the article's original conclusions.

**7. Extra Credit (1 pt)**
Develop an interactive Shiny app to visualize your machine learning model's projections. The app must include at least one interactive widget (e.g., dropdown, radio buttons, text input) allowing users to select a variable value (such as country/region) and view the corresponding projections.


**Submission**

* You will upload the zip file containing finals.Rmd file and its PDF as a deliverable to Canvas. If you created a shiny app for predictions, you will add those files also to your zip file.

* You will present your findings by creating a video of a maximum 15 minutes duration, explaining the code and the workings of your project; all team members should explain their part in the project to receive credit. You will share the URL of the video on Canvas for us to evaluate. An ideal way to create this video would be to start a Zoom meeting, start recording, and then every member share their screen and explain their contribution.


It is not necessary to prepare slides (if you do it doesn't hurt) for the presentation. You may speak by showing the diagrams and/or code from your Posit project.  Every team member should explain their part in the project along with the insights they derived by explaining the charts and summaries for full credit to each member.

Your project will be evaluated for clean code, meaningful/insightful EDA and predictions.

**Note:**

* Each plot must be accompanied by a summary that clarifies the rationale behind its creation and what insights the plot unveils. Every diagram should possess standalone significance, revealing something more compelling than the other charts
* After the deadline, instructors will select the top three outstanding analytics projects. The teams responsible for these exceptional analyses will have their video shared with the class

**We will not accept submissions after the deadline; December 10th 4 pm**



